\subsection{Streaming RAW video using Python}\label{subsec:python}
To test some of the ideas mentioned in section \ref{sec:Theory}, a python prototype program was constructed. The program is limited to transmitting RAW video data, since encoding it introduced quite a lot of additional complexity in handling packages and stitching it together on the client side.\\

The implementation consists of a server that broadcasts a video stream, included in appendix A, and a client that displays the received video stream, included in appendix B.

\subsubsection{Requirements}\label{subsubsec:requirements}
To run the python script, are few requirements a needed, as listed below,

\begin{enumerate}
    \item Make sure you are running python version 2.7.x, since OpenCV does not work under python 3.x.
    \item Install OpenCV (Intel Open Source Computer Vision Library) from \href{http://opencv.org}{http://opencv.org}.
    \item Install numpy from \href{http://www.numpy.org}{http://www.numpy.org}.
\end{enumerate}


\subsubsection{Architecture}
The architecture of the python implementation is a bit simpler than a final implementation would look like. Figure \ref{fig:PythonImplementation} shows an overview of the implementation in an easily digestable way.

\Fig[1]{PythonImplementation}{Overview of the python implementation}

As seen, the server first takes the video feed from the webcam. This could be substituted for a file, if needed. To actually interact with the webcam and perform operations on image frames, we use OpenCV, as discussed in the requirements in section \ref{subsubsec:requirements}.

Once we have an image frame, we resize the frame on the server side, to that we transmit varying data, depending on the resolution we resize to. Now, to actually transmit the frame, we have to convert it to a string since the frame is in the form of a matrix when OpenCV handles it.

The final steps on the server side, is to in the beginning of each frame, transmit a synchronization keyword, which also holds the information about the resolution of the frame that is coming. After this, the image frame, which is now represented as a string, is divided into smaller chunks, and then each chunk is sent broadcast out on an UDP connection.\\

The client first connects to the servers UDP broadcast. It then waits for the synchronization keyword, so it knows a frame has started. It then reads the resolution part of the synchronization keyword, and adjusts to this. After the sync has been performed, it reads packages until a fixed size is reached. Since we are transmitting RAW data, we can calculate the size as, width $\cdot$ height $\cdot$ depth $=$ full frame size. 

After it has gathered a full frame, it then converts the frame back from the string representation, into a image matrix. We then resize the image frame back to the dimensions of our video player.

Finally, we can either display the image frame directly, or we can encode the frame and write it to a file. The encoding would ideally have been handled at the server side, but it was easier to do on the client side, for the sake of prototyping.


\subsubsection{Usage}
A local setup where both the server and client resides on the same machine is the easiest way to get things going. Alternatively, the IP and port numbers can be adjusted in the script. They are found inside the \textit{\_\_init\_\_} methods of each of the server and client objects.\\

First, start the server with \textit{python streamer\_server.py}. Once the server shows a menu of different resolutions it is broadcasting the video feed from the computers webcam (can alternatively be switched to use a file instead). 

The client can now be started with \textit{python streamer\_client.py}. The client will connect to the server, and automatically synchronize so it reads from the beginning of each frame and displays it when it has received a full frame. Resolution is adjusted by the server, and is sent along with a synchronization keyword.\\

The client will display some statistics during the transmission, presuming the script is run in a terminal (on the command line). If the text keeps making new lines, adjust the width of the terminal until it just updates the current line.

It is now possible to change the resolution during the transmission, from the server side. This is supposed mimic the drone switching to a lower bit rate, when the signal worsens. The client automatically adjusts, and the statistics changes.\\


\subsubsection{Problems}
Since the implementation sends RAW video frames, they take up quite a lot of bandwidth. One advantage to RAW video frames is that all frames have the same size, since there hasn't been any information compressed or removed. This makes it a bit easier to handle, when splitting up the image into packages (they are too large to send directly through a network socket).\\

Furthermore, the client can quite keep up with the server transmission, when it also has to transform the frames to something displayable and show it. This is shown by the drop in fps, when the resolution is higher. The lower the resolution is, the higher the fps gets, since the client has to do less work, and less bandwidth is also used. It will cap though at the fps of the transmission, which during testing was around 30 fps.

\subsection{Streaming compressed video from Drone}
% Forklar kort om hvordan vi simulerer en drone ved hjælp af en Android telefon
It is obvious, that during so short period of time it isn't possible to build a drone from scratch, make it work and do real video streaming from the drone to a server. Therefore it was decided to make an Android application that will act like a drone. The Android application is nothing like a real drone, but the Android application is a far better testing environment rather than testing locally on a computer. Because the Android application is low on resources regarding CPU, RAM and network processing, it will be a much better testing environment that is closer to the obstructions of supplying a streaming service for a functional drone.

\subsubsection{Requirements}
% Beskriv de nødvendige programmer

To run the Drone application, some few requirements are needed, as listed below,\\

\noindent\textbf{Android}
\begin{enumerate}
    \item Smartphone with Android 4.4.x (KitKat) or later
        \subitem Make sure to allow installation of third-party apps
    \item Download the latest .apk from \href{https://github.com/martinjlowm/34220_project_variable_bit_rate/raw/master/android/DroneStreamer/releases/}{this repository}
\end{enumerate}

\noindent\textbf{Server}
\begin{enumerate}
    \item Install VLC media player 2.1.2 (Rincewind) or later from \href{http://www.videolan.org/}{http://www.videolan.org/}
    \item Run command: \texttt{vlc udp://@:10000}
        \subitem This will make VLC start listening for incoming UDP data at port 10000
\end{enumerate}


\subsubsection{Architecture}
The basic architecture are as show on Figure \ref{fig:drone}. The drone will be caring a camera that is recording and sending the raw data into an encoder. The encoder will, based on the current type op network and signal quality, be resized, compressed and get quality adjustments. When the data is compressed it will be broadcasted through the wireless network by using an UDP connection to the receiver. Furthermore the drone will send some signals to tell the server what the network conditions are and what kind of video format, quality and compression level to expect. This will be monitoring with the video at the end display.

\Fig[1]{drone}{Overview for the drone application}

\subsubsection{Usage}
As before mentioned, there isn't enough time to make a drone from scratch, so it was decided to make an Android application. To get things working the requirements needs to be met. When all the requirements are forfilled, open the application with the name Drone Streamer (Figure \ref{fig:androidIcon}).

\Fig[0.4]{androidIcon}{Launch icon for the Android application}

When the application is open, enter the ip specific ip and port in the textfield (Figure \ref{fig:androidApp} for the target server (where VLC media player is installed).

\Fig[0.6]{androidApp}{The interface of the Drone Streamer Android application.}

\textbf{IMPORTANT!} Before clicking one of the buttons in the application, which indicates the resolution to stream - go the the folder where VLC is installed and start VLC by using the following command:

\begin{verbatim}
> vlc udp://@:10000
\end{verbatim}

The command will start VLC and make it listen for UDP traffic on the port 10000. Enter the port number to match with the one set in the Android application.
When VLC is started, choose a resolution and press the desired button to start the streaming process. Be patient as VLC has to buffer some data before it will show the video.\\

\textbf{IMPORTANT!} When you want to start a new stream or choose another resolution, close down the Android application - to do this, use the task manager that Android provides. Furthermore close down the VLC media player and do the same as described above.

\subsubsection{Resource limitations}
% Forklar udfordringerne ved at streame video fra en drone
Trying to create a streaming application for a drone isn't as easy as it may sound. A drone has a limited amount of resources, such as RAM, CPUand most important battery lifetime because it needs a lot of resources for other components like GPS, steering, motors etc. Therefore it's very important that the streaming service dosn't use too much resources and are effecient. Even though this project are using an Android smartphone to simulate the streaming service, these problems still occur and there has been a lot struggling with the limiting amount of resources. Accordingly it's prefered to create dedicated hardware to process the video compressing to minimize the use of resources. Due to the time limit the project will not cover this area of concern.

\subsubsection{Deploying FFmpeg to an Android application}
% Forklar hvordan man får FFmpeg til at virke på en android telefon, og hvordan man indkapsler ffmpeg i en android applikation i en JNI
To stream and compress video in an Android application the FFmpeg project is needed to be included into the application. The FFmpeg project is a good choice because it has all the functionalities that are needed for this type of streaming service. Unfortunately the FFmpeg isn't that easy to implement into an Android application. To implement the source code of the FFmpeg project has to be download and rebuild to fit the system architecture the specific Android smartphone is using - in this case, the FFmpeg project is compiled to fit to an ARM processor.

\subsubsection{Transfer video to the server}
% Hvordan får vi videoen hen på serveren og hvordan viser vi den? - dette gør vi ved at sende video fra telefonen over udp til en bestemt ip og port, hvor serveren så lytter på dette
