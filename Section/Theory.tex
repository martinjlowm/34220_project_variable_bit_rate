To allow a drone to cast a stable video stream to a distant server, the loss of an efficient data rate must be countered. Using MPEG codecs, we can reduce the need of the total transmitted bits. Depending on the video feed and its use cases, the compression strength can be chosen and tested to find a proper value which requires a low bit rate while keeping a desired video quality.

In the case of a drone transmitting a feed, this compression must adapt to the quality of the network. A poor wireless network quality reduces how much can be transmitted and the video may experience stuttering frames. The desired video stream is a smooth, stutterless video with images of high quality when possible. 

\subsection{Compressing video}
A way of reducing the data being sent is by compressing the data. While this affects the image sligthly in loss of quality, it allows us to reduce the data size of a video. Audio is transferred as well and will also affect the final experience.

\subsubsection{Adjustable parameters}
Like the human ear is limited to a set of frequencies it may experience, the human eye is limited in the number of shades it can see. Thus, by reducing the color space in a video, the resulting experience of that video will reduce the amount of data drastically while providing a sufficient image. MPEG uses a mathematical algorithm, \textit{discrete cosine transform}, DCT and Huffman coding in combination with run-length coding to find places in an image where this data can be reduced.

Another method used to further compress the data is to track movement in a series of images and predict how the images will look. In theory, this way only the moving parts' data is transmitted. The image at the receiver is then reconstructed using the original image known as the I-frame with the snapshot of the moving parts known as the P-frame. In between these frames bidirectional predictions are sent, known as B-frames that take less data to describe the image. The difference between P- and B-frames are their reference frame.
% forklar de forskellige paramtre man kan justere på - framerate, format, farver, kvalitet etc.

To sum up, by encoding using standard MPEG we can accomplish a reduced bit rate with a similar quality to the original using the above parameters. In our approach we attempt to use these and also change resolution and frame rate.

The above methods in MPEG requires extra computing of the CPU, which may slow down the system. Therefore, decoding methods are often implemented in hardware.

\subsection{Compressing video using FFmpeg}
% hvordan kan man komprimere video ved hjælp af FFmpeg
We use FFmpeg as a utility to access MPEG coding. FFmpeg is a very flexible tool which allows us to test a wide variety of codecs and it handles most of the video processing.

FFmpeg can be understood as a multiple input and single output unit which can multiplex a set of media files. For example, it can multiplex an audio- and video recording. To refer to a simple use case, the utility is called in a UNIX-fashion as:
\begin{center}
\begin{verbatim}
ffmpeg -i input.mp4 -i input.mp3 -map 0:0 -map 1:0 -vcodec copy
-acodec copy output.mp4
\end{verbatim}
\end{center}
The output video file is generated with sound mapped from the audio input file to the video stream of the video input. These two streams are joined and output to a video file. Both codecs used in the two original files are copied and used for the final file.

\subsection{Protocols for streaming video}
When choosing to stream video, different protocols are available. First comes the choice of whether to use TCP or UDP. Briefly explained, the differences between the two is that TCP sets up a connection (it is connection-oriented), and cares about both packet order and if the packets are received or not. UDP on the other hand is a connection-less protocol and simply transmits the packet, and it is then up to the receiver to decide, in the application layer typically, if a packet needs to be resend.

Typically TCP isn't used when live-streaming, since it adds a lot of overhead and enforces a specific order of received data. Concerning packet loss, a buffer most be present, so the lost ones can be resent. When multiple clients are connected, resources can slowly begin to become a problem.

UDP on the other hand doesn't care about this. It also allows the use of IP multicast, which is very suitable for more than one receiver.\\

To sum up, UDP is recommended, especially in an environment where the signal quality will vary, and packets can be lost.
